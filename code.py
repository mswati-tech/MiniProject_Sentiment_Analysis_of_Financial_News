# -*- coding: utf-8 -*-
"""code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WnwT-kjgTqROCCSWhw2bQ78QKZe_sUly
"""

#INSTALLING & IMPORTING DEPENDENCIES

#!pip install gensim
#!pip install gensim pyLDAvis nltk

#Code block for importing all rquired and necessary dependencies

try:
  import pandas as pd
  import numpy as np
  import matplotlib.pyplot as plt
  from wordcloud import WordCloud
  import re
  import nltk
  from nltk.stem import WordNetLemmatizer
  from nltk.corpus import stopwords
  from nltk.sentiment.vader import SentimentIntensityAnalyzer
  nltk.download('vader_lexicon')
  nltk.download('punkt')
  nltk.download('stopwords')
  nltk.download('wordnet')

  from sklearn.feature_extraction.text import TfidfVectorizer
  from sklearn.feature_extraction.text import CountVectorizer
  from sklearn.model_selection import train_test_split
  from sklearn.linear_model import LogisticRegression
  from sklearn.svm import SVC
  from sklearn.naive_bayes import ComplementNB
  from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report

  import tensorflow as tf
  from tensorflow.keras.models import Sequential
  from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional
  from transformers import BertTokenizer, BertForSequenceClassification
  from transformers import pipeline
  from sklearn.metrics import accuracy_score, classification_report
  from tensorflow.keras.preprocessing.text import Tokenizer
  from tensorflow.keras.preprocessing.sequence import pad_sequences

  from gensim import corpora, models
  from gensim.models import Word2Vec
  import pyLDAvis.gensim_models as gensimvis
  import pyLDAvis
  from IPython.display import display

  import warnings
  warnings.filterwarnings("ignore", category=DeprecationWarning)

  print("Libraries installed and imported successfully")

except ImportError:
  print("Error importing libraries")

except ModuleNotFoundError:
  print("Error: module not found")

except ValueError:
  print("Error: value error")

else:
  print("All modules were imported and this is the 'else' block exceuting")

finally:
  print("Import Complete.")

  #DATASET INPUT

  #Loading the filename into a dataframe, splitting by newlines as each entry is a news snippet
  file_name = "FinNews.txt"

  try:
    #Opening the file and reading each line
    with open(file_name, "r", encoding="utf-8") as f:
      lines = f.read().splitlines()

  except FileNotFoundError:
    print(f"Error: The file '{file_name}' was not found.")
    lines = []

  except Exception as e:
    print(f"An error occurred: {e}")
    lines = []

  #Creating a dataframe from the list of lines
  df = pd.DataFrame(lines, columns=["headlines"])

  #Removing empty entries
  df = df.dropna()

  #Printing the dataframe: Checkpoint
  print(df)

  #TEXT CLEANING & PRE-PROCESSING

  stop_words = set(stopwords.words('english'))
  lemmatizer = WordNetLemmatizer()

  def clean_text(text):
    #Converting the text to lowercase
    text = text.lower()

    #Removing punctuations, numbers, and special characters
    words = re.sub(r'[^a-zA-Z]', ' ', text)

    #Tokenizing
    words = words.split()

    #Removing stopwords
    words = [word for word in words if word not in stop_words]

    #Lemmatizing
    words = [lemmatizer.lemmatize(word) for word in words]

    #Since NLTK's Vader uses a lexicon-based approach so we need to compile the each headline as a string
    return " ".join(words)

  #Applying the function clean_text on each headline
  df['clean_headlines'] = df['headlines'].apply(clean_text)

  #Printing the updated dataframe: Checkpoint
  print(df)

  #VADER-BASED SENTIMENTAL ANALYSIS

  #The list 'labels' will be used for supervised learning and counting the sentiments
  labels = []

  count_p = 0 #For counting the positive headlines
  count_n = 0 #For counting the negative headlines
  count_z = 0 #For counting the neutral headlines

  analyzer = SentimentIntensityAnalyzer() #Created obj 'analyzer' of the SentimentIntensityAnalyzer class

  #Looping through the dataframe
  for news in df['clean_headlines']:
    score = analyzer.polarity_scores(news) #Getting the polarity scores for each headline
    if score['compound'] > 0:
      labels.append("@positive")
      count_p += 1
    elif score['compound'] < 0:
      labels.append("@negative")
      count_n += 1
    else:
      labels.append("@neutral")
      count_z += 1

  #Adding the labels to the dataframe
  df['labels'] = labels

  #Printing the updated dataframe: Checkpoint
  print(df)

  #Printing the summary
  print("\nSummary:")
  print("\nThe number of positive headlines is: ", count_p)
  print("\nThe number of negative headlines is: ", count_n)
  print("\nThe number of neutral headlines is: ", count_z)

  #Visualizing the Bar graph of Sentiment Analysis Vader result
  plt.bar(["Positive"], count_p, color = "green")
  plt.bar(["Negative"], count_n, color = "red")
  plt.bar(["Neutal"], count_z, color = "black")
  plt.title("Sentiment Analysis of Headlines")
  plt.xlabel("Sentiments")
  plt.ylabel("Number of Headlines")
  plt.show()

  #Visualizing the Word Cloud of Sentiment Analysis Vader result for each sentiment
  sentiments = ["@positive", "@negative", "@neutral"]
  colors = {"@positive":"green", "@negative":"red", "@neutral":"black"}

  # Display the generated image
  for sentiment in sentiments:
    text = " ".join(df[df['labels'] == sentiment]['clean_headlines'])
    if text.strip() != "":
        wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)
        plt.figure(figsize=(10,5))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis('off')
        plt.title(f"Word Cloud of {sentiment} Headlines", color=colors[sentiment])
        plt.show()

  #IMPLEMENTING MACHINE LEARNING MODELS: LOGISITIC REGRESSION (LR), SUPPORT VECTOR MACHINE (SVM), NAIVE BAYES (NB)

  #Feature extraction using TF-IDF and converting text to numerical vectors

  vectorizer_tfidf = TfidfVectorizer()  #Creating vectorizer 'obj' of the class TfidfVectorizer for LR and SVM
  vectorizer_count = CountVectorizer()  #Creating vectorizer 'obj' of the class CountVectorizer for NB

  """Naive Bayes (MultinomialNB / ComplementNB) expects word counts (discrete frequencies).
  TF-IDF gives fractional, normalized weights. That makes NB’s probability calculations less natural, because it assumes integer counts.
  So, NB often performs better with CountVectorizer than TF-IDF."""

  X = vectorizer_tfidf.fit_transform(df['clean_headlines'])  #X entries
  y = df['labels']  #Y labels

  X_nb = vectorizer_count.fit_transform(df['clean_headlines'])  #X entries for NB
  y_nb = df['labels']  #Y labels for NB

  #Splitting the data
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) #Training dataset is 80% and test size is 20% for LR, SVM
  X_train_nb, X_test_nb, y_train_nb, y_test_nb = train_test_split(X_nb, y_nb, test_size=0.2, random_state=42) #Training dataset is 80% and test size is 20% for NB

  """From Sentiment Analysis- VADER, we found that the positive and neutral headlines are far greater in number than the negative headlines.
  Therefore, we need to train the model to penalize mistakes on the minority class more. Therefore, I will provide such parameters to 'balance'
  the bias."""

  #Training the LR, SVM, NB
  lr_model = LogisticRegression(max_iter=1000, random_state= 42, class_weight="balanced") #LR
  lr_model.fit(X_train, y_train)

  svm_model = SVC(kernel='poly', random_state=42, class_weight="balanced")  #SVM: 'Poly' is because the dataset appears to be non-linear
  svm_model.fit(X_train, y_train)

  """I have used ComplementNB rather than the standard MultinomialNB because of the imbalanced dataset"""

  nb_model = ComplementNB(alpha=0.1, fit_prior=True)  #'alpha=0.1' is the smoothing of the biased dataset and fit_prior = True treats the bias in the dataset
  nb_model.fit(X_train_nb, y_train_nb)

  #Predicting
  y_pred_lr = lr_model.predict(X_test)  #LR
  y_pred_svm = svm_model.predict(X_test)  #SVM
  y_pred_nb = nb_model.predict(X_test_nb)  #NB

  #Evaluating
  print("\n\n FOR LOGISTIC REGRESSION:")
  print("\nClassification Report:",classification_report(y_test,y_pred_lr))
  print("\nConfusion Matrix:", confusion_matrix(y_test,y_pred_lr))

  print("\n\n FOR SUPPORT VECTOR CLASSIFIER:")
  print("\nClassification Report:", classification_report(y_test,y_pred_svm))
  print("\nConfusion Matrix:", confusion_matrix(y_test,y_pred_svm))

  print("\n\n FOR COMPLEMENT NAIVE BAYES:")
  print("\nClassification Report:", classification_report(y_test_nb, y_pred_nb))
  print("\nConfusion Matrix:", confusion_matrix(y_test_nb, y_pred_nb))

  #IMPLEMENTING DEEP LEARNING ALGORITHMS: LSTM & BERT FOR A MINISET OF 50 HEADLINES AND COMPARING EACH WITH VADER

  #Mini-set for comparison because my laptop configuration would not support it for the entire dataset

  mini_df = df.head(50)  #first 50 headlines

  #Preparing VADER labels

  analyzer = SentimentIntensityAnalyzer()
  vader_labels = []

  for news in mini_df['clean_headlines']:
    score = analyzer.polarity_scores(news)
    if score['compound'] > 0:
      vader_labels.append(2)  #positive
    elif score['compound'] < 0:
      vader_labels.append(0)  #negative
    else:
      vader_labels.append(1)  #neutral

  #Preparing FinBERT labels

  """pipeline("sentiment-analysis") -> This is a Hugging Face Transformers utility that creates an easy-to-use sentiment analysis tool. You just give it text, and it outputs sentiment scores and labels.
  model="yiyanghkust/finbert-tone" -> This specifies the pre-trained FinBERT model trained specifically for financial text sentiment analysis (positive, neutral, negative).
  device=-1 → This tells the pipeline to run on CPU. (0 would use the first GPU if available.)"""

  finbert = pipeline("sentiment-analysis", model="yiyanghkust/finbert-tone", device=-1)  #CPU

  #finbert(h)[0] is an object called like a function on each headline.

  finbert_results = [finbert(h)[0] for h in mini_df['clean_headlines']]

  """r['label'] -> gets the label string from each dictionary in finbert_results.
  .lower() -> converts the label to lowercase ("Positive" → "positive"), so it matches our mapping dictionary.
  {"positive":2, "neutral":1, "negative":0} -> converts the string label into a numeric code:
  [ ... for r in finbert_results ] → applies this conversion for every headline."""


  finbert_labels = [{"positive":2, "neutral":1, "negative":0}[r['label'].lower()] for r in finbert_results]

  #Preparing LSTM labels

  #Tokenizing mini-set

  tokenizer = Tokenizer(num_words=2000, oov_token="<OOV>") #instanting the class Tokenizer
  tokenizer.fit_on_texts(df['clean_headlines'])  #fit on full dataset
  X_seq_mini = tokenizer.texts_to_sequences(mini_df['clean_headlines']) #tokenize and vectorize

  max_len = 50
  X_pad_mini = pad_sequences(X_seq_mini, maxlen=max_len, padding='post')  #Padding will smoothen out and create inputs of same length

  lstm_model = Sequential([
  Embedding(input_dim=2000, output_dim=32, input_length=max_len),
  LSTM(16, return_sequences=False),
  Dense(3, activation='softmax')
  ])

  lstm_model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  # lstm_model.fit(...)  # Train on your training data

  y_pred_lstm_mini = lstm_model.predict(X_pad_mini) #Predicting for each headline

  """Since LSTM will predict probability for each class for a single headline row, we will only consider the class with
  probability as the headline label"""

  lstm_labels = np.argmax(y_pred_lstm_mini, axis=1)

  #Preparing “ground truth". I have used VADER as pseudo ground-truth
  y_true = vader_labels

  #Accuracy & Classification
  print("\nMini-set Comparison (50 headlines)")

  #LSTM vs VADER
  print("\nLSTM Accuracy / Agreement with VADER:", accuracy_score(y_true, lstm_labels))
  print("LSTM Classification Report:\n", classification_report(y_true, lstm_labels))

  #FinBERT vs VADER
  print("\nFinBERT Accuracy / Agreement with VADER:", accuracy_score(y_true, finbert_labels))
  print("FinBERT Classification Report:\n", classification_report(y_true, finbert_labels))

  #Combining into a DataFrame for side-by-side comparison
  comparison_df = mini_df[['headlines']].copy()
  comparison_df['VADER'] = vader_labels
  comparison_df['LSTM'] = lstm_labels
  comparison_df['FinBERT'] = finbert_labels

  print("\nSide-by-side comparison:")
  print(comparison_df)

  #TOPIC MODELLING WITH LDA

  #Tokenizing Headlines
  tokenized_docs = [headline.split() for headline in df['clean_headlines']]  #simple whitespace tokenization

  #Creating dictionary and bag-of-words corpus
  dictionary = corpora.Dictionary(tokenized_docs)        #maps word -> id
  corpus_bow = [dictionary.doc2bow(text) for text in tokenized_docs]  #bag-of-words representation

  #Training the LDA model
  lda_model = models.LdaModel(
  corpus=corpus_bow,
  id2word=dictionary,
  num_topics=3,
  passes=5,
  random_state=42
  )

  #Printing topics
  for idx, topic in lda_model.print_topics(-1):
    print(f"Topic {idx+1}: {topic}")

  #Visualization
  pyLDAvis.enable_notebook()
  vis = gensimvis.prepare(lda_model, corpus_bow, dictionary)
  display(vis)

  #Assigning dominant topic to each headline
  doc_topics = []
  for row in lda_model[corpus_bow]:
    row = sorted(row, key=lambda x: x[1], reverse=True)
    dominant_topic, topic_prob = row[0]
    doc_topics.append([dominant_topic+1, topic_prob])  # topics numbered 1-3

  #Converting to dataframe and adding the dominant topic
  doc_topic_df = pd.DataFrame(doc_topics, columns=["Dominant_Topic", "Topic_Prob"])
  df["Dominant_Topic"] = doc_topic_df["Dominant_Topic"]
  df["Topic_Prob"] = doc_topic_df["Topic_Prob"]

  #Saving to File
  df.to_csv("Financial_News_with_topics.txt", index=False)
  print(df.head(10))